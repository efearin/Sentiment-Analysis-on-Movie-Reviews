{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PURPOSE OF CODE\n",
    "\n",
    "Cleaning meaningless words and punctuations to prepare data to further train and test datasets seperation. Since test data should also be cleaned before scoring, this process shifted to the beginning and done over whole data before test and train devision."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PROCESS NOTES\n",
    "\n",
    "WILL BE DONE\n",
    " - ..\\AppData\\Roaming\\nltk_data\\corpora\\stopwords\\english_redesigned document could be checked for stopwords\n",
    "\n",
    "DONE\n",
    "- all phrases are lowered\n",
    "- stemmed using nltk PorterStemmer\n",
    "- punctuations are erased\n",
    "- stop words (nltk library pre created stop words list is redesigned to use) are erased\n",
    "- dublicate phrases with different sentiment scores are averaged\n",
    "- saved as clean-data.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get data \"../data/data.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PhraseId</th>\n",
       "      <th>SentenceId</th>\n",
       "      <th>Phrase</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>90</td>\n",
       "      <td>3</td>\n",
       "      <td>Ismail</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>91</td>\n",
       "      <td>3</td>\n",
       "      <td>Merchant 's</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>92</td>\n",
       "      <td>3</td>\n",
       "      <td>Merchant</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>93</td>\n",
       "      <td>3</td>\n",
       "      <td>'s</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    PhraseId  SentenceId       Phrase  Sentiment\n",
       "89        90           3       Ismail          2\n",
       "90        91           3  Merchant 's          2\n",
       "91        92           3     Merchant          2\n",
       "92        93           3           's          2"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.core.debugger import Tracer; debug = Tracer()\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "df=pd.read_csv('data/data.csv',sep=\"\\t\")\n",
    "df[89:93]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Replace capitals to non-capitals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PhraseId</th>\n",
       "      <th>SentenceId</th>\n",
       "      <th>Phrase</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>90</td>\n",
       "      <td>3</td>\n",
       "      <td>ismail</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>91</td>\n",
       "      <td>3</td>\n",
       "      <td>merchant 's</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>92</td>\n",
       "      <td>3</td>\n",
       "      <td>merchant</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>93</td>\n",
       "      <td>3</td>\n",
       "      <td>'s</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    PhraseId  SentenceId       Phrase  Sentiment\n",
       "89        90           3       ismail          2\n",
       "90        91           3  merchant 's          2\n",
       "91        92           3     merchant          2\n",
       "92        93           3           's          2"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.Phrase=df.Phrase.str.lower()\n",
    "df[89:93]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are no 'isn't', 'arent', 'havent' or such words in data, they all have already changed to their not seperated forms like \"is not\" . For example check for 'isn't'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "haha=0\n",
    "for x in df.Phrase.str.contains(\" isn't\"):\n",
    "    if x:\n",
    "        haha+=1\n",
    "haha"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stem the data using nltk PorterStemmer which changes the words like \"pythoner\", \"pythoning\" etc. to the \"python\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from nltk.stem import PorterStemmer\n",
    "ps=PorterStemmer()\n",
    "\n",
    "def stemming(x):\n",
    "    proper_words=[]\n",
    "    words=x.split()\n",
    "    for word in words:\n",
    "        proper_words.append(ps.stem(word))\n",
    "    return \" \".join(proper_words)\n",
    "\n",
    "df.Phrase=df.Phrase.map(stemming)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove punctuations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PhraseId</th>\n",
       "      <th>SentenceId</th>\n",
       "      <th>Phrase</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>90</td>\n",
       "      <td>3</td>\n",
       "      <td>ismail</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>91</td>\n",
       "      <td>3</td>\n",
       "      <td>merchant s</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>92</td>\n",
       "      <td>3</td>\n",
       "      <td>merchant</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>93</td>\n",
       "      <td>3</td>\n",
       "      <td>s</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    PhraseId  SentenceId      Phrase  Sentiment\n",
       "89        90           3      ismail          2\n",
       "90        91           3  merchant s          2\n",
       "91        92           3    merchant          2\n",
       "92        93           3           s          2"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.Phrase = df.Phrase.str.replace('[^\\w\\s]','')\n",
    "df[89:93]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "nltk's english stopwords list at location \"..\\AppData\\Roaming\\nltk_data\\corpora\\stopwords\" includes words like \"no\", \"not\". They changes the meaning in sentiment analysis since if \"no\" is erased from data \"not good\" and \"good\" scored as same. So such stopwords are removed from pre-created list of nltk library.\n",
    "\n",
    "The words erased from list are\n",
    "\"not, no, very, too, up, down, in, out, over, under, few\"\n",
    "\n",
    "Check again if miss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PhraseId</th>\n",
       "      <th>SentenceId</th>\n",
       "      <th>Phrase</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>90</td>\n",
       "      <td>3</td>\n",
       "      <td>ismail</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>91</td>\n",
       "      <td>3</td>\n",
       "      <td>merchant</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>92</td>\n",
       "      <td>3</td>\n",
       "      <td>merchant</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>93</td>\n",
       "      <td>3</td>\n",
       "      <td></td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    PhraseId  SentenceId    Phrase  Sentiment\n",
       "89        90           3    ismail          2\n",
       "90        91           3  merchant          2\n",
       "91        92           3  merchant          2\n",
       "92        93           3                    2"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#import redesigned stopword list named as \"english_redesigned\" from nltk\n",
    "from nltk.corpus import stopwords\n",
    "stopwords_set = set(stopwords.words('english_redesigned'))\n",
    "\n",
    "#define a map to delete stopwords under each phrase\n",
    "def stop_erase(x):\n",
    "    proper_words = []\n",
    "    words = x.split()\n",
    "    for word in words:\n",
    "        if not word in stopwords_set:\n",
    "           proper_words.append(word)\n",
    "        \n",
    "    return \" \".join(proper_words)\n",
    "\n",
    "df.Phrase=df.Phrase.map(stop_erase)\n",
    "df[89:93]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PhraseId</th>\n",
       "      <th>SentenceId</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>156060.000000</td>\n",
       "      <td>156060.000000</td>\n",
       "      <td>156060.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>78030.500000</td>\n",
       "      <td>4079.732744</td>\n",
       "      <td>2.063578</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>45050.785842</td>\n",
       "      <td>2502.764394</td>\n",
       "      <td>0.893832</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>39015.750000</td>\n",
       "      <td>1861.750000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>78030.500000</td>\n",
       "      <td>4017.000000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>117045.250000</td>\n",
       "      <td>6244.000000</td>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>156060.000000</td>\n",
       "      <td>8544.000000</td>\n",
       "      <td>4.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            PhraseId     SentenceId      Sentiment\n",
       "count  156060.000000  156060.000000  156060.000000\n",
       "mean    78030.500000    4079.732744       2.063578\n",
       "std     45050.785842    2502.764394       0.893832\n",
       "min         1.000000       1.000000       0.000000\n",
       "25%     39015.750000    1861.750000       2.000000\n",
       "50%     78030.500000    4017.000000       2.000000\n",
       "75%    117045.250000    6244.000000       3.000000\n",
       "max    156060.000000    8544.000000       4.000000"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.to_csv(\"data/data-clean.csv\", sep='\\t')\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done succesfully\n"
     ]
    }
   ],
   "source": [
    "print(\"done succesfully\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
