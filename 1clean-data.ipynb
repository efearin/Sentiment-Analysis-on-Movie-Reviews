{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PURPOSE OF CODE\n",
    "\n",
    "Cleaning meaningless words and punctuations to prepare data to further train and test datasets seperation. Since test data should also be cleaned before scoring, this process shifted to the beginning and done over whole data before test and train devision."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PROCESS NOTES\n",
    "\n",
    "WILL BE DONE\n",
    " - ..\\AppData\\Roaming\\nltk_data\\corpora\\stopwords\\english_redesigned document could be checked for stopwords\n",
    "\n",
    "DONE\n",
    "- all phrases are lowered\n",
    "- stemmed using nltk PorterStemmer\n",
    "- punctuations are erased\n",
    "- stop words (nltk library pre created stop words list is redesigned to use) are erased\n",
    "- saved as clean-data.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get data \"../data/data.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PhraseId</th>\n",
       "      <th>SentenceId</th>\n",
       "      <th>Phrase</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>This quiet , introspective and entertaining in...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    PhraseId  SentenceId                                             Phrase  \\\n",
       "63        64           2  This quiet , introspective and entertaining in...   \n",
       "\n",
       "    Sentiment  \n",
       "63          4  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.core.debugger import Tracer; debug = Tracer()\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "df=pd.read_csv('data/data.csv',sep=\"\\t\")\n",
    "df[63:64]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Replace capitals to non-capitals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PhraseId</th>\n",
       "      <th>SentenceId</th>\n",
       "      <th>Phrase</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>this quiet , introspective and entertaining in...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    PhraseId  SentenceId                                             Phrase  \\\n",
       "63        64           2  this quiet , introspective and entertaining in...   \n",
       "\n",
       "    Sentiment  \n",
       "63          4  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.Phrase=df.Phrase.str.lower()\n",
    "df[63:64]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are no 'isn't', 'arent', 'havent' or such words in data, they all have already changed to their not seperated forms like \"is not\" . For example check for 'isn't'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "haha=0\n",
    "for x in df.Phrase.str.contains(\" isn't\"):\n",
    "    if x:\n",
    "        haha+=1\n",
    "haha"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stem the data using nltk PorterStemmer which changes the words like \"pythoner\", \"pythoning\" etc. to the \"python\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from nltk.stem import PorterStemmer\n",
    "ps=PorterStemmer()\n",
    "\n",
    "def stemming(x):\n",
    "    proper_words=[]\n",
    "    words=x.split()\n",
    "    for word in words:\n",
    "        proper_words.append(ps.stem(word))\n",
    "    return \" \".join(proper_words)\n",
    "\n",
    "df.Phrase=df.Phrase.map(stemming)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PhraseId</th>\n",
       "      <th>SentenceId</th>\n",
       "      <th>Phrase</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>thi quiet , introspect and entertain independ ...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    PhraseId  SentenceId                                             Phrase  \\\n",
       "63        64           2  thi quiet , introspect and entertain independ ...   \n",
       "\n",
       "    Sentiment  \n",
       "63          4  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[63:64]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove punctuations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PhraseId</th>\n",
       "      <th>SentenceId</th>\n",
       "      <th>Phrase</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>thi quiet  introspect and entertain independ i...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    PhraseId  SentenceId                                             Phrase  \\\n",
       "63        64           2  thi quiet  introspect and entertain independ i...   \n",
       "\n",
       "    Sentiment  \n",
       "63          4  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.Phrase = df.Phrase.str.replace('[^\\w\\s]','')\n",
    "df[63:64]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "nltk's english stopwords list at location \"..\\AppData\\Roaming\\nltk_data\\corpora\\stopwords\" includes words like \"no\", \"not\". They changes the meaning in sentiment analysis since if \"no\" is erased from data \"not good\" and \"good\" scored as same. So such stopwords are removed from pre-created list of nltk library.\n",
    "\n",
    "The words erased from list are\n",
    "\"not, no, very, too, up, down, in, out, over, under, few\"\n",
    "\n",
    "Check again if miss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PhraseId</th>\n",
       "      <th>SentenceId</th>\n",
       "      <th>Phrase</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>thi quiet introspect entertain independ worth ...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    PhraseId  SentenceId                                             Phrase  \\\n",
       "63        64           2  thi quiet introspect entertain independ worth ...   \n",
       "\n",
       "    Sentiment  \n",
       "63          4  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#import redesigned stopword list named as \"english_redesigned\" from nltk\n",
    "from nltk.corpus import stopwords\n",
    "stopwords_set = set(stopwords.words('english_redesigned'))\n",
    "\n",
    "#define a map to delete stopwords under each phrase\n",
    "def stop_erase(x):\n",
    "    proper_words = []\n",
    "    words = x.split()\n",
    "    for word in words:\n",
    "        if not word in stopwords_set:\n",
    "           proper_words.append(word)\n",
    "        \n",
    "    return \" \".join(proper_words)\n",
    "\n",
    "df.Phrase=df.Phrase.map(stop_erase)\n",
    "df[63:64]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PhraseId</th>\n",
       "      <th>SentenceId</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>156060.000000</td>\n",
       "      <td>156060.000000</td>\n",
       "      <td>156060.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>78030.500000</td>\n",
       "      <td>4079.732744</td>\n",
       "      <td>2.063578</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>45050.785842</td>\n",
       "      <td>2502.764394</td>\n",
       "      <td>0.893832</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>39015.750000</td>\n",
       "      <td>1861.750000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>78030.500000</td>\n",
       "      <td>4017.000000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>117045.250000</td>\n",
       "      <td>6244.000000</td>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>156060.000000</td>\n",
       "      <td>8544.000000</td>\n",
       "      <td>4.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            PhraseId     SentenceId      Sentiment\n",
       "count  156060.000000  156060.000000  156060.000000\n",
       "mean    78030.500000    4079.732744       2.063578\n",
       "std     45050.785842    2502.764394       0.893832\n",
       "min         1.000000       1.000000       0.000000\n",
       "25%     39015.750000    1861.750000       2.000000\n",
       "50%     78030.500000    4017.000000       2.000000\n",
       "75%    117045.250000    6244.000000       3.000000\n",
       "max    156060.000000    8544.000000       4.000000"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.to_csv(\"data/copdata-clean.csv\", sep='\\t')\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done succesfully\n"
     ]
    }
   ],
   "source": [
    "print(\"done succesfully\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
