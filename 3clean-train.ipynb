{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PhraseId</th>\n",
       "      <th>SentenceId</th>\n",
       "      <th>Phrase</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>140593</td>\n",
       "      <td>7629</td>\n",
       "      <td>yakusho alway wonder longfac sad sack hi chemi...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>93544</td>\n",
       "      <td>4877</td>\n",
       "      <td>flick guy</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>31590</td>\n",
       "      <td>1479</td>\n",
       "      <td>countless</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>13873</td>\n",
       "      <td>596</td>\n",
       "      <td>earn uplift</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>152452</td>\n",
       "      <td>8319</td>\n",
       "      <td>no clear pictur kill bob crane</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PhraseId  SentenceId                                             Phrase  \\\n",
       "0    140593        7629  yakusho alway wonder longfac sad sack hi chemi...   \n",
       "1     93544        4877                                          flick guy   \n",
       "2     31590        1479                                          countless   \n",
       "3     13873         596                                        earn uplift   \n",
       "4    152452        8319                     no clear pictur kill bob crane   \n",
       "\n",
       "   Sentiment  \n",
       "0          4  \n",
       "1          2  \n",
       "2          2  \n",
       "3          3  \n",
       "4          1  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "df=pd.read_csv('data/train.csv',sep=\"\\t\")\n",
    "df = df.drop('Unnamed: 0', 1)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Replace empty phrase rows to NaN then delete."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#print(\"size of data with empty phrase rows=\",len(df.index))\n",
    "\n",
    "#define a map to change empty phrases to NaN\n",
    "def change_nan(x):\n",
    "    if pd.isnull(x):\n",
    "        return np.nan \n",
    "    if len(x) == 0:\n",
    "        return np.nan\n",
    "    return x\n",
    "\n",
    "df['Phrase'] = df.Phrase.map(change_nan)\n",
    "\n",
    "#remove NaN rows of df\n",
    "df=df.dropna()\n",
    "\n",
    "#reset indexing\n",
    "df=df.reset_index(drop=True)\n",
    "\n",
    "#print(\"size of data after empty phrase rows deleted=\",len(df.index))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Afer clean, the same same phrases with differen sentiment scores created as follows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PhraseId                                                 140593\n",
       "SentenceId                                                 7629\n",
       "Phrase        yakusho alway wonder longfac sad sack hi chemi...\n",
       "Sentiment                                                     4\n",
       "Name: 0, dtype: object"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for x in df.Phrase:\n",
    "    same=df.Phrase[df.Phrase==x]\n",
    "    if len(same.index)>1:\n",
    "        break\n",
    "df.loc[same.index[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PhraseId                                                 140594\n",
       "SentenceId                                                 7629\n",
       "Phrase        yakusho alway wonder longfac sad sack hi chemi...\n",
       "Sentiment                                                     3\n",
       "Name: 26006, dtype: object"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[same.index[1]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Take a phrase as referance to the \"phrase\" list. Find the same ones in data and record the indexes to the \"same\" list. In such same phrase groups assign the first one as referance by changing its sentiment score to group average and change other phrases to NaN to remove later from the list. Before doing that sentiment scores should be converted into float data type from intiger(as a default)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#print(\"data type of sentiment scores= \",df.Sentiment.dtype)\n",
    "\n",
    "#convert sentiment scores to float to write averaged ones\n",
    "df.Sentiment=df.Sentiment.astype(float)\n",
    "df.dtypes\n",
    "#print(\"data type of sentiment scores after conversion= \",df.Sentiment.dtype)\n",
    "\n",
    "#write size of data before merge\n",
    "#print(\"data size before merge= \",len(df.index))\n",
    "\n",
    "#\"phrase\" holds the current phrase to compare through whole set and find the indexes of same other phrase rows \n",
    "#which will written in \"same\"\n",
    "#then they will changed to NaN for further clean process\n",
    "#summation holds the summation of same phrase sentiment scores that will avaraged and written to the first phrase among all same phrases\n",
    "same=[]\n",
    "summation=0\n",
    "phrase=[]\n",
    "\n",
    "for index,row in df.iterrows():\n",
    "    if row.Phrase!=np.nan :\n",
    "        same=df.Phrase[df.Phrase==row.Phrase]\n",
    "        if len(same.index)>1:\n",
    "            summation=0\n",
    "            phrase=df.loc[same.index[0],'Phrase']\n",
    "            for x in range(1,len(same.index)):\n",
    "                df.loc[same.index[x],'Phrase']=np.nan\n",
    "                summation+=df.loc[same.index[x],'Sentiment']\n",
    "            summation+=df.loc[same.index[0],'Sentiment']\n",
    "            df.loc[same.index[0],'Sentiment']=summation/len(same.index)\n",
    "\n",
    "#clean all NaN rows\n",
    "df=df.dropna()\n",
    "\n",
    "#write size of data after merge\n",
    "#print(\"data size after merge= \",len(df.index))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove NaN assigneds and reindex data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PhraseId</th>\n",
       "      <th>SentenceId</th>\n",
       "      <th>Phrase</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>140593</td>\n",
       "      <td>7629</td>\n",
       "      <td>yakusho alway wonder longfac sad sack hi chemi...</td>\n",
       "      <td>3.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>93544</td>\n",
       "      <td>4877</td>\n",
       "      <td>flick guy</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>31590</td>\n",
       "      <td>1479</td>\n",
       "      <td>countless</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>13873</td>\n",
       "      <td>596</td>\n",
       "      <td>earn uplift</td>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>152452</td>\n",
       "      <td>8319</td>\n",
       "      <td>no clear pictur kill bob crane</td>\n",
       "      <td>1.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>96410</td>\n",
       "      <td>5036</td>\n",
       "      <td>attempt make film relev today without fulli un...</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>84521</td>\n",
       "      <td>4373</td>\n",
       "      <td>fairi tale</td>\n",
       "      <td>2.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>122338</td>\n",
       "      <td>6557</td>\n",
       "      <td>not tick hum</td>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>99668</td>\n",
       "      <td>5228</td>\n",
       "      <td>alli</td>\n",
       "      <td>2.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>153089</td>\n",
       "      <td>8360</td>\n",
       "      <td>theori</td>\n",
       "      <td>2.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>6239</td>\n",
       "      <td>248</td>\n",
       "      <td>first</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>32127</td>\n",
       "      <td>1505</td>\n",
       "      <td>pain slow clicheridden film fill hole clyde ba...</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>142967</td>\n",
       "      <td>7760</td>\n",
       "      <td>iron</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>50044</td>\n",
       "      <td>2456</td>\n",
       "      <td>heartwarm without stoop gooey</td>\n",
       "      <td>4.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>144790</td>\n",
       "      <td>7859</td>\n",
       "      <td>jump in chair</td>\n",
       "      <td>2.500000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    PhraseId  SentenceId                                             Phrase  \\\n",
       "0     140593        7629  yakusho alway wonder longfac sad sack hi chemi...   \n",
       "1      93544        4877                                          flick guy   \n",
       "2      31590        1479                                          countless   \n",
       "3      13873         596                                        earn uplift   \n",
       "4     152452        8319                     no clear pictur kill bob crane   \n",
       "5      96410        5036  attempt make film relev today without fulli un...   \n",
       "6      84521        4373                                         fairi tale   \n",
       "7     122338        6557                                       not tick hum   \n",
       "8      99668        5228                                               alli   \n",
       "9     153089        8360                                             theori   \n",
       "10      6239         248                                              first   \n",
       "11     32127        1505  pain slow clicheridden film fill hole clyde ba...   \n",
       "12    142967        7760                                               iron   \n",
       "13     50044        2456                      heartwarm without stoop gooey   \n",
       "14    144790        7859                                      jump in chair   \n",
       "\n",
       "    Sentiment  \n",
       "0    3.500000  \n",
       "1    2.000000  \n",
       "2    2.000000  \n",
       "3    3.000000  \n",
       "4    1.750000  \n",
       "5    2.000000  \n",
       "6    2.250000  \n",
       "7    3.000000  \n",
       "8    2.500000  \n",
       "9    2.333333  \n",
       "10   2.000000  \n",
       "11   1.000000  \n",
       "12   2.000000  \n",
       "13   4.000000  \n",
       "14   2.500000  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=df.dropna()\n",
    "df=df.reset_index(drop=True)\n",
    "df.head(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This cleaned data is sort of vocabulary list. Save file as train-clean.csv under data folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PhraseId</th>\n",
       "      <th>SentenceId</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>75819.000000</td>\n",
       "      <td>75819.000000</td>\n",
       "      <td>75819.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>79360.938116</td>\n",
       "      <td>4152.322320</td>\n",
       "      <td>2.063092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>44736.596744</td>\n",
       "      <td>2488.383312</td>\n",
       "      <td>0.880306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>40970.000000</td>\n",
       "      <td>1964.000000</td>\n",
       "      <td>1.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>79814.000000</td>\n",
       "      <td>4112.000000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>118160.500000</td>\n",
       "      <td>6312.000000</td>\n",
       "      <td>2.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>156060.000000</td>\n",
       "      <td>8544.000000</td>\n",
       "      <td>4.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            PhraseId    SentenceId     Sentiment\n",
       "count   75819.000000  75819.000000  75819.000000\n",
       "mean    79360.938116   4152.322320      2.063092\n",
       "std     44736.596744   2488.383312      0.880306\n",
       "min         1.000000      1.000000      0.000000\n",
       "25%     40970.000000   1964.000000      1.666667\n",
       "50%     79814.000000   4112.000000      2.000000\n",
       "75%    118160.500000   6312.000000      2.666667\n",
       "max    156060.000000   8544.000000      4.000000"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.to_csv(\"data/train-clean.csv\", sep='\\t')\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done succesfully\n"
     ]
    }
   ],
   "source": [
    "print(\"done succesfully\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
