{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PhraseId</th>\n",
       "      <th>SentenceId</th>\n",
       "      <th>Phrase</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>104018</td>\n",
       "      <td>5485</td>\n",
       "      <td>less dens plot</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>38706</td>\n",
       "      <td>1844</td>\n",
       "      <td>aspir</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>44785</td>\n",
       "      <td>2171</td>\n",
       "      <td>never flag</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>98230</td>\n",
       "      <td>5148</td>\n",
       "      <td>elud madonna</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>77780</td>\n",
       "      <td>3999</td>\n",
       "      <td>enjoy mindless action movi</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PhraseId  SentenceId                      Phrase  Sentiment\n",
       "0    104018        5485              less dens plot          2\n",
       "1     38706        1844                       aspir          2\n",
       "2     44785        2171                  never flag          2\n",
       "3     98230        5148                elud madonna          2\n",
       "4     77780        3999  enjoy mindless action movi          2"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "df=pd.read_csv('data/train.csv',sep=\"\\t\")\n",
    "df = df.drop('Unnamed: 0', 1)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Replace empty phrase rows to NaN then delete."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "size of data with empty phrase rows= 124848\n",
      "size of data after empty phrase rows deleted= 124207\n"
     ]
    }
   ],
   "source": [
    "#print(\"size of data with empty phrase rows=\",len(df.index))\n",
    "\n",
    "#define a map to change empty phrases to NaN\n",
    "def change_nan(x):\n",
    "    if pd.isnull(x):\n",
    "        return np.nan \n",
    "    if len(x) == 0:\n",
    "        return np.nan\n",
    "    return x\n",
    "\n",
    "df['Phrase'] = df.Phrase.map(change_nan)\n",
    "\n",
    "#remove NaN rows of df\n",
    "df=df.dropna()\n",
    "\n",
    "#reset indexing\n",
    "df=df.reset_index(drop=True)\n",
    "\n",
    "#print(\"size of data after empty phrase rows deleted=\",len(df.index))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Afer clean, the same same phrases with differen sentiment scores created as follows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-31-7bbccdaa5eb6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mPhrase\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0msame\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mPhrase\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mPhrase\u001b[0m\u001b[1;33m==\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msame\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m>\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[1;32mbreak\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0msame\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\efear\\Anaconda3\\lib\\site-packages\\pandas\\core\\ops.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(self, other, axis)\u001b[0m\n\u001b[1;32m    853\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    854\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0merrstate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mall\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'ignore'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 855\u001b[0;31m                 \u001b[0mres\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mna_op\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mother\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    856\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0misscalar\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mres\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    857\u001b[0m                 raise TypeError('Could not compare %s type with Series' %\n",
      "\u001b[0;32mC:\\Users\\efear\\Anaconda3\\lib\\site-packages\\pandas\\core\\ops.py\u001b[0m in \u001b[0;36mna_op\u001b[0;34m(x, y)\u001b[0m\n\u001b[1;32m    757\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    758\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mis_object_dtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 759\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_comp_method_OBJECT_ARRAY\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mop\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    760\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    761\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for x in df.Phrase:\n",
    "    same=df.Phrase[df.Phrase==x]\n",
    "    if len(same.index)>1:\n",
    "        break\n",
    "df.loc[same.index[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df.loc[same.index[1]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Take a phrase as referance to the \"phrase\" list. Find the same ones in data and record the indexes to the \"same\" list. In such same phrase groups assign the first one as referance by changing its sentiment score to group average and change other phrases to NaN to remove later from the list. Before doing that sentiment scores should be converted into float data type from intiger(as a default)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data type of sentiment scores=  int64\n",
      "data type of sentiment scores after conversion=  float64\n",
      "data size before merge=  124207\n",
      "data size after merge=  75657\n"
     ]
    }
   ],
   "source": [
    "#print(\"data type of sentiment scores= \",df.Sentiment.dtype)\n",
    "\n",
    "#convert sentiment scores to float to write averaged ones\n",
    "df.Sentiment=df.Sentiment.astype(float)\n",
    "df.dtypes\n",
    "#print(\"data type of sentiment scores after conversion= \",df.Sentiment.dtype)\n",
    "\n",
    "#write size of data before merge\n",
    "#print(\"data size before merge= \",len(df.index))\n",
    "\n",
    "#\"phrase\" holds the current phrase to compare through whole set and find the indexes of same other phrase rows \n",
    "#which will written in \"same\"\n",
    "#then they will changed to NaN for further clean process\n",
    "#summation holds the summation of same phrase sentiment scores that will avaraged and written to the first phrase among all same phrases\n",
    "same=[]\n",
    "summation=0\n",
    "phrase=[]\n",
    "\n",
    "for index,row in df.iterrows():\n",
    "    if row.Phrase!=np.nan :\n",
    "        same=df.Phrase[df.Phrase==row.Phrase]\n",
    "        if len(same.index)>1:\n",
    "            summation=0\n",
    "            phrase=df.loc[same.index[0],'Phrase']\n",
    "            for x in range(1,len(same.index)):\n",
    "                df.loc[same.index[x],'Phrase']=np.nan\n",
    "                summation+=df.loc[same.index[x],'Sentiment']\n",
    "            summation+=df.loc[same.index[0],'Sentiment']\n",
    "            df.loc[same.index[0],'Sentiment']=summation/len(same.index)\n",
    "\n",
    "#clean all NaN rows\n",
    "df=df.dropna()\n",
    "\n",
    "#write size of data after merge\n",
    "#print(\"data size after merge= \",len(df.index))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove NaN assigneds and reindex data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PhraseId</th>\n",
       "      <th>SentenceId</th>\n",
       "      <th>Phrase</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>104018</td>\n",
       "      <td>5485</td>\n",
       "      <td>less dens plot</td>\n",
       "      <td>1.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>38706</td>\n",
       "      <td>1844</td>\n",
       "      <td>aspir</td>\n",
       "      <td>2.142857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>44785</td>\n",
       "      <td>2171</td>\n",
       "      <td>never flag</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>98230</td>\n",
       "      <td>5148</td>\n",
       "      <td>elud madonna</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>77780</td>\n",
       "      <td>3999</td>\n",
       "      <td>enjoy mindless action movi</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>92189</td>\n",
       "      <td>4798</td>\n",
       "      <td>help screenplay lrb profici singularli cursori...</td>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>152143</td>\n",
       "      <td>8300</td>\n",
       "      <td>disturb world delic ecolog balanc</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>150979</td>\n",
       "      <td>8230</td>\n",
       "      <td>unexplain baboon cameo</td>\n",
       "      <td>1.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>55094</td>\n",
       "      <td>2747</td>\n",
       "      <td>unspeak unbear dull featur ream flatli deliv d...</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>151451</td>\n",
       "      <td>8259</td>\n",
       "      <td>total loss</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>73700</td>\n",
       "      <td>3769</td>\n",
       "      <td>attent</td>\n",
       "      <td>2.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>82356</td>\n",
       "      <td>4251</td>\n",
       "      <td>gryffindor scarf</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>7088</td>\n",
       "      <td>285</td>\n",
       "      <td>ii</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>68897</td>\n",
       "      <td>3500</td>\n",
       "      <td>testament de niro director michael catonjon</td>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>131320</td>\n",
       "      <td>7076</td>\n",
       "      <td>gere in hi danc shoe</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    PhraseId  SentenceId                                             Phrase  \\\n",
       "0     104018        5485                                     less dens plot   \n",
       "1      38706        1844                                              aspir   \n",
       "2      44785        2171                                         never flag   \n",
       "3      98230        5148                                       elud madonna   \n",
       "4      77780        3999                         enjoy mindless action movi   \n",
       "5      92189        4798  help screenplay lrb profici singularli cursori...   \n",
       "6     152143        8300                  disturb world delic ecolog balanc   \n",
       "7     150979        8230                             unexplain baboon cameo   \n",
       "8      55094        2747  unspeak unbear dull featur ream flatli deliv d...   \n",
       "9     151451        8259                                         total loss   \n",
       "10     73700        3769                                             attent   \n",
       "11     82356        4251                                   gryffindor scarf   \n",
       "12      7088         285                                                 ii   \n",
       "13     68897        3500        testament de niro director michael catonjon   \n",
       "14    131320        7076                               gere in hi danc shoe   \n",
       "\n",
       "    Sentiment  \n",
       "0    1.666667  \n",
       "1    2.142857  \n",
       "2    2.000000  \n",
       "3    2.000000  \n",
       "4    2.000000  \n",
       "5    3.000000  \n",
       "6    2.000000  \n",
       "7    1.500000  \n",
       "8    0.000000  \n",
       "9    0.666667  \n",
       "10   2.333333  \n",
       "11   2.000000  \n",
       "12   2.000000  \n",
       "13   3.000000  \n",
       "14   2.000000  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=df.dropna()\n",
    "df=df.reset_index(drop=True)\n",
    "df.head(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This cleaned data is sort of vocabulary list. Save file as train-clean.csv under data folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PhraseId</th>\n",
       "      <th>SentenceId</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>75657.000000</td>\n",
       "      <td>75657.000000</td>\n",
       "      <td>75657.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>79324.027836</td>\n",
       "      <td>4150.265805</td>\n",
       "      <td>2.063290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>44739.678914</td>\n",
       "      <td>2488.595072</td>\n",
       "      <td>0.877785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>40892.000000</td>\n",
       "      <td>1960.000000</td>\n",
       "      <td>1.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>79694.000000</td>\n",
       "      <td>4103.000000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>118190.000000</td>\n",
       "      <td>6313.000000</td>\n",
       "      <td>2.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>156060.000000</td>\n",
       "      <td>8544.000000</td>\n",
       "      <td>4.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            PhraseId    SentenceId     Sentiment\n",
       "count   75657.000000  75657.000000  75657.000000\n",
       "mean    79324.027836   4150.265805      2.063290\n",
       "std     44739.678914   2488.595072      0.877785\n",
       "min         2.000000      1.000000      0.000000\n",
       "25%     40892.000000   1960.000000      1.666667\n",
       "50%     79694.000000   4103.000000      2.000000\n",
       "75%    118190.000000   6313.000000      2.666667\n",
       "max    156060.000000   8544.000000      4.000000"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.to_csv(\"data/train-clean.csv\", sep='\\t')\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(\"done succesfully\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
