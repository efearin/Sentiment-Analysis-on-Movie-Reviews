{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PURPOSE OF CODE\n",
    "\n",
    "Cleaning meaningless words and punctuations to prepare data to further train and test datasets seperation. Since test data should also be cleaned before scoring this process shifted to the beginning and done over whole data before test and train devision."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PROCESS NOTES\n",
    "\n",
    "WILL BE DONE\n",
    " - ..\\AppData\\Roaming\\nltk_data\\corpora\\stopwords\\english_redesigned document could be checked for stopwords\n",
    " - numbers should be changed to their word forms\n",
    "\n",
    "DONE\n",
    "- all phrases are lowered\n",
    "- stemmed using nltk PorterStemmer\n",
    "- punctuations are erased\n",
    "- stop words (nltk library pre created stop words list is redesigned to use) are erased\n",
    "- dublicate phrases with different sentiment scores are averaged\n",
    "- saved as clean-data.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get data under folder /data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PhraseId</th>\n",
       "      <th>SentenceId</th>\n",
       "      <th>Phrase</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>90</td>\n",
       "      <td>3</td>\n",
       "      <td>Ismail</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>91</td>\n",
       "      <td>3</td>\n",
       "      <td>Merchant 's</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>92</td>\n",
       "      <td>3</td>\n",
       "      <td>Merchant</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>93</td>\n",
       "      <td>3</td>\n",
       "      <td>'s</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    PhraseId  SentenceId       Phrase  Sentiment\n",
       "89        90           3       Ismail          2\n",
       "90        91           3  Merchant 's          2\n",
       "91        92           3     Merchant          2\n",
       "92        93           3           's          2"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.core.debugger import Tracer; debug = Tracer()\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "df=pd.read_csv('data/data.csv',sep=\"\\t\")\n",
    "df[89:93]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Replace capitals to non-capitals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PhraseId</th>\n",
       "      <th>SentenceId</th>\n",
       "      <th>Phrase</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>90</td>\n",
       "      <td>3</td>\n",
       "      <td>ismail</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>91</td>\n",
       "      <td>3</td>\n",
       "      <td>merchant 's</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>92</td>\n",
       "      <td>3</td>\n",
       "      <td>merchant</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>93</td>\n",
       "      <td>3</td>\n",
       "      <td>'s</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    PhraseId  SentenceId       Phrase  Sentiment\n",
       "89        90           3       ismail          2\n",
       "90        91           3  merchant 's          2\n",
       "91        92           3     merchant          2\n",
       "92        93           3           's          2"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.Phrase=df.Phrase.str.lower()\n",
    "df[89:93]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are no 'isn't', 'arent', 'havent' or such words in data, they all have already changed to their not seperated forms like \"is not\" . For example check for 'isn't'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "haha=0\n",
    "for x in df.Phrase.str.contains(\" isn't\"):\n",
    "    if x:\n",
    "        haha+=1\n",
    "haha"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stem the data using nltk PorterStemmer which changes the words like \"pythoner\", \"pythoning\" etc. to the \"python\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from nltk.stem import PorterStemmer\n",
    "ps=PorterStemmer()\n",
    "\n",
    "def stemming(x):\n",
    "    proper_words=[]\n",
    "    words=x.split()\n",
    "    for word in words:\n",
    "        proper_words.append(ps.stem(word))\n",
    "    return \" \".join(proper_words)\n",
    "\n",
    "df.Phrase=df.Phrase.map(stemming)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove punctuations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PhraseId</th>\n",
       "      <th>SentenceId</th>\n",
       "      <th>Phrase</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>90</td>\n",
       "      <td>3</td>\n",
       "      <td>ismail</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>91</td>\n",
       "      <td>3</td>\n",
       "      <td>merchant s</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>92</td>\n",
       "      <td>3</td>\n",
       "      <td>merchant</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>93</td>\n",
       "      <td>3</td>\n",
       "      <td>s</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    PhraseId  SentenceId      Phrase  Sentiment\n",
       "89        90           3      ismail          2\n",
       "90        91           3  merchant s          2\n",
       "91        92           3    merchant          2\n",
       "92        93           3           s          2"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.Phrase = df.Phrase.str.replace('[^\\w\\s]','')\n",
    "df[89:93]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "nltk's english stopwords list at location \"..\\AppData\\Roaming\\nltk_data\\corpora\\stopwords\" includes words like \"no\", \"not\". They changes the meaning in sentiment analysis since if \"no\" is erased from data \"not good\" and \"good\" scored as same. So stopwords are removed by using redesigned form of pre-created list of nltk library.\n",
    "\n",
    "The words erased from list are\n",
    "\"not, no, very, too, up, down, in, out, over, under, few\"\n",
    "\n",
    "Check again if miss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PhraseId</th>\n",
       "      <th>SentenceId</th>\n",
       "      <th>Phrase</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>90</td>\n",
       "      <td>3</td>\n",
       "      <td>ismail</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>91</td>\n",
       "      <td>3</td>\n",
       "      <td>merchant</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>92</td>\n",
       "      <td>3</td>\n",
       "      <td>merchant</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>93</td>\n",
       "      <td>3</td>\n",
       "      <td></td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    PhraseId  SentenceId    Phrase  Sentiment\n",
       "89        90           3    ismail          2\n",
       "90        91           3  merchant          2\n",
       "91        92           3  merchant          2\n",
       "92        93           3                    2"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#import redesigned stopword list named as \"english_redesigned\" from nltk\n",
    "from nltk.corpus import stopwords\n",
    "stopwords_set = set(stopwords.words('english_redesigned'))\n",
    "\n",
    "#define a map to delete stopwords under each phrase\n",
    "def stop_erase(x):\n",
    "    proper_words = []\n",
    "    words = x.split()\n",
    "    for word in words:\n",
    "        if not word in stopwords_set:\n",
    "           proper_words.append(word)\n",
    "        \n",
    "    return \" \".join(proper_words)\n",
    "\n",
    "df.Phrase=df.Phrase.map(stop_erase)\n",
    "df[89:93]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Replace empty phrase rows to NaN then delete."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "size of data with empty phrase rows= 156060\n",
      "size of data after empty phrase rows deleted= 155259\n"
     ]
    }
   ],
   "source": [
    "print(\"size of data with empty phrase rows=\",len(df.index))\n",
    "\n",
    "#define a map to change empty phrases to NaN\n",
    "def change_nan(x):\n",
    "    if pd.isnull(x):\n",
    "        return np.nan \n",
    "    if len(x) == 0:\n",
    "        return np.nan\n",
    "    return x\n",
    "\n",
    "df['Phrase'] = df.Phrase.map(change_nan)\n",
    "\n",
    "#remove NaN rows of df\n",
    "df=df.dropna()\n",
    "\n",
    "#reset indexing\n",
    "df=df.reset_index(drop=True)\n",
    "\n",
    "print(\"size of data after empty phrase rows deleted=\",len(df.index))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Afer clean, the same same phrases with differen sentiment scores created as follows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PhraseId</th>\n",
       "      <th>SentenceId</th>\n",
       "      <th>Phrase</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "      <td>good goos</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>22</td>\n",
       "      <td>1</td>\n",
       "      <td>good goos</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    PhraseId  SentenceId     Phrase  Sentiment\n",
       "14        20           1  good goos          2\n",
       "15        22           1  good goos          3"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[14:16]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Take a phrase as referance to the \"phrase\" list. Find the same ones in data and record the indexes to the \"same\" list. In such same phrase groups assign the first one as referance by changing its sentiment score to group average and change other phrases to NaN to remove later from the list. Before doing that sentiment scores should be converted into float data type from intiger(as a default)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data type of sentiment scores=  int64\n",
      "data type of sentiment scores after conversion=  float64\n",
      "data size before merge=  155259\n",
      "data size after merge=  85812\n"
     ]
    }
   ],
   "source": [
    "print(\"data type of sentiment scores= \",df.Sentiment.dtype)\n",
    "\n",
    "#convert sentiment scores to float to write averaged ones\n",
    "df.Sentiment=df.Sentiment.astype(float)\n",
    "df.dtypes\n",
    "print(\"data type of sentiment scores after conversion= \",df.Sentiment.dtype)\n",
    "\n",
    "#write size of data before merge\n",
    "print(\"data size before merge= \",len(df.index))\n",
    "\n",
    "#\"phrase\" holds the current phrase to compare through whole set and find the indexes of same other phrase rows \n",
    "#which will written in \"same\"\n",
    "#then they will changed to NaN for further clean process\n",
    "#summation holds the summation of same phrase sentiment scores that will avaraged and written to the first phrase among all same phrases\n",
    "same=[]\n",
    "summation=0\n",
    "phrase=[]\n",
    "\n",
    "for index,row in df.iterrows():\n",
    "    if row.Phrase!=np.nan :\n",
    "        same=df.Phrase[df.Phrase==row.Phrase]\n",
    "        if len(same.index)>1:\n",
    "            summation=0\n",
    "            phrase=df.loc[same.index[0],'Phrase']\n",
    "            for x in range(1,len(same.index)):\n",
    "                df.loc[same.index[x],'Phrase']=np.nan\n",
    "                summation+=df.loc[same.index[x],'Sentiment']\n",
    "            summation+=df.loc[same.index[0],'Sentiment']\n",
    "            df.loc[same.index[0],'Sentiment']=summation/len(same.index)\n",
    "\n",
    "#clean all NaN rows\n",
    "df=df.dropna()\n",
    "\n",
    "#write size of data after merge\n",
    "print(\"data size after merge= \",len(df.index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PhraseId</th>\n",
       "      <th>SentenceId</th>\n",
       "      <th>Phrase</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "      <td>good gander occasion amus none amount much stori</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "      <td>gander occasion amus none amount much stori</td>\n",
       "      <td>1.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    PhraseId  SentenceId                                            Phrase  \\\n",
       "24        32           1  good gander occasion amus none amount much stori   \n",
       "25        33           1       gander occasion amus none amount much stori   \n",
       "\n",
       "    Sentiment  \n",
       "24        2.0  \n",
       "25        1.5  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[14:16]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove NaN assigneds and reindex data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PhraseId</th>\n",
       "      <th>SentenceId</th>\n",
       "      <th>Phrase</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>seri escapad demonstr adag good goos also good...</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>seri escapad demonstr adag good goos</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>seri</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>escapad demonstr adag good goos</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>escapad</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>demonstr adag good goos</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>demonstr adag</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>demonstr</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>adag</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>good goos</td>\n",
       "      <td>2.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>23</td>\n",
       "      <td>1</td>\n",
       "      <td>good</td>\n",
       "      <td>2.717949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>24</td>\n",
       "      <td>1</td>\n",
       "      <td>goos</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>28</td>\n",
       "      <td>1</td>\n",
       "      <td>also good gander occasion amus none amount muc...</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>30</td>\n",
       "      <td>1</td>\n",
       "      <td>also</td>\n",
       "      <td>2.090909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "      <td>good gander occasion amus none amount much stori</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    PhraseId  SentenceId                                             Phrase  \\\n",
       "0          1           1  seri escapad demonstr adag good goos also good...   \n",
       "1          2           1               seri escapad demonstr adag good goos   \n",
       "2          3           1                                               seri   \n",
       "3          6           1                    escapad demonstr adag good goos   \n",
       "4          9           1                                            escapad   \n",
       "5         10           1                            demonstr adag good goos   \n",
       "6         11           1                                      demonstr adag   \n",
       "7         12           1                                           demonstr   \n",
       "8         13           1                                               adag   \n",
       "9         16           1                                          good goos   \n",
       "10        23           1                                               good   \n",
       "11        24           1                                               goos   \n",
       "12        28           1  also good gander occasion amus none amount muc...   \n",
       "13        30           1                                               also   \n",
       "14        32           1   good gander occasion amus none amount much stori   \n",
       "\n",
       "    Sentiment  \n",
       "0    1.000000  \n",
       "1    2.000000  \n",
       "2    2.000000  \n",
       "3    2.000000  \n",
       "4    2.000000  \n",
       "5    2.000000  \n",
       "6    2.000000  \n",
       "7    2.000000  \n",
       "8    2.000000  \n",
       "9    2.250000  \n",
       "10   2.717949  \n",
       "11   2.000000  \n",
       "12   2.000000  \n",
       "13   2.090909  \n",
       "14   2.000000  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=df.dropna()\n",
    "df=df.reset_index(drop=True)\n",
    "df.head(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This cleaned data is sort of vocabulary list. Save file as cleandf.csv under data folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PhraseId</th>\n",
       "      <th>SentenceId</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>85812.000000</td>\n",
       "      <td>85812.000000</td>\n",
       "      <td>85812.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>76983.701732</td>\n",
       "      <td>4023.147462</td>\n",
       "      <td>2.060142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>45395.101649</td>\n",
       "      <td>2519.421455</td>\n",
       "      <td>0.869558</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>37399.750000</td>\n",
       "      <td>1776.000000</td>\n",
       "      <td>1.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>76569.000000</td>\n",
       "      <td>3938.000000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>116410.250000</td>\n",
       "      <td>6207.000000</td>\n",
       "      <td>2.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>156060.000000</td>\n",
       "      <td>8544.000000</td>\n",
       "      <td>4.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            PhraseId    SentenceId     Sentiment\n",
       "count   85812.000000  85812.000000  85812.000000\n",
       "mean    76983.701732   4023.147462      2.060142\n",
       "std     45395.101649   2519.421455      0.869558\n",
       "min         1.000000      1.000000      0.000000\n",
       "25%     37399.750000   1776.000000      1.666667\n",
       "50%     76569.000000   3938.000000      2.000000\n",
       "75%    116410.250000   6207.000000      2.500000\n",
       "max    156060.000000   8544.000000      4.000000"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.to_csv(\"data/clean-data.csv\", sep='\\t')\n",
    "df.describe()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
