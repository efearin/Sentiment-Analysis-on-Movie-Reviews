{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\efear\\Anaconda3\\lib\\site-packages\\gensim-2.1.0-py3.6-win-amd64.egg\\gensim\\utils.py:860: UserWarning: detected Windows; aliasing chunkize to chunkize_serial\n",
      "  warnings.warn(\"detected Windows; aliasing chunkize to chunkize_serial\")\n",
      "Slow version of gensim.models.doc2vec is being used\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import gensim, logging"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clean data using \"1clean-data.ipynb\"\n",
    "Takes input \"../data/data.csv\"\n",
    "Outputs a \"../data/clean-data.csv\" file. \n",
    "For details see \"1clean-data.ipynb\" itself."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done succesfully\n"
     ]
    }
   ],
   "source": [
    "%run \"1clean-data.ipynb\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Devide data using \"2devide-data.ipynb\"\n",
    "Takes input \"../data/clean-data.csv\" file.\n",
    "Outputs \"../data/1df.csv\", \"../data/2df.csv\" ... \"../data/5df.csv\"\n",
    "For details see \"2devide-data.ipynb\" itself."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done succesfully\n"
     ]
    }
   ],
   "source": [
    "%run \"2devide-data.ipynb\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create train and test sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done succesfully\n",
      "done succesfully\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-06-22 14:05:03,891 : WARNING : Slow version of gensim.models.word2vec is being used\n",
      "2017-06-22 14:05:03,893 : INFO : collecting all words and their counts\n",
      "2017-06-22 14:05:03,894 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2017-06-22 14:05:03,914 : INFO : collected 11665 word types from a corpus of 84428 raw words and 8423 sentences\n",
      "2017-06-22 14:05:03,915 : INFO : Loading a fresh vocabulary\n",
      "2017-06-22 14:05:03,938 : INFO : min_count=1 retains 11665 unique words (100% of original 11665, drops 0)\n",
      "2017-06-22 14:05:03,940 : INFO : min_count=1 leaves 84428 word corpus (100% of original 84428, drops 0)\n",
      "2017-06-22 14:05:03,974 : INFO : deleting the raw counts dictionary of 11665 items\n",
      "2017-06-22 14:05:03,976 : INFO : sample=0.001 downsamples 29 most-common words\n",
      "2017-06-22 14:05:03,977 : INFO : downsampling leaves estimated 78623 word corpus (93.1% of prior 84428)\n",
      "2017-06-22 14:05:03,979 : INFO : estimated required memory for 11665 words and 100 dimensions: 15164500 bytes\n",
      "2017-06-22 14:05:04,013 : INFO : resetting layer weights\n",
      "C:\\Users\\efear\\Anaconda3\\lib\\site-packages\\gensim-2.1.0-py3.6-win-amd64.egg\\gensim\\models\\word2vec.py:789: UserWarning: C extension not loaded for Word2Vec, training will be slow. Install a C compiler and reinstall gensim for fast training.\n",
      "  warnings.warn(\"C extension not loaded for Word2Vec, training will be slow. \"\n",
      "2017-06-22 14:05:04,183 : INFO : training model with 3 workers on 11665 vocabulary and 100 features, using sg=0 hs=0 sample=0.001 negative=5 window=5\n",
      "2017-06-22 14:05:11,428 : INFO : PROGRESS: at 2.46% examples, 1283 words/s, in_qsize 5, out_qsize 0\n",
      "2017-06-22 14:05:18,676 : INFO : PROGRESS: at 9.65% examples, 2571 words/s, in_qsize 6, out_qsize 0\n",
      "2017-06-22 14:05:25,925 : INFO : PROGRESS: at 16.67% examples, 2997 words/s, in_qsize 5, out_qsize 0\n",
      "2017-06-22 14:05:33,166 : INFO : PROGRESS: at 23.77% examples, 3213 words/s, in_qsize 5, out_qsize 0\n",
      "2017-06-22 14:05:40,388 : INFO : PROGRESS: at 30.97% examples, 3343 words/s, in_qsize 5, out_qsize 0\n",
      "2017-06-22 14:05:41,438 : INFO : PROGRESS: at 35.67% examples, 3749 words/s, in_qsize 6, out_qsize 0\n",
      "2017-06-22 14:05:47,625 : INFO : PROGRESS: at 37.95% examples, 3429 words/s, in_qsize 5, out_qsize 0\n",
      "2017-06-22 14:05:48,627 : INFO : PROGRESS: at 40.27% examples, 3561 words/s, in_qsize 5, out_qsize 0\n",
      "2017-06-22 14:05:54,881 : INFO : PROGRESS: at 45.11% examples, 3490 words/s, in_qsize 5, out_qsize 0\n",
      "2017-06-22 14:05:56,007 : INFO : PROGRESS: at 47.53% examples, 3594 words/s, in_qsize 6, out_qsize 0\n",
      "2017-06-22 14:06:02,142 : INFO : PROGRESS: at 52.23% examples, 3535 words/s, in_qsize 5, out_qsize 0\n",
      "2017-06-22 14:06:03,448 : INFO : PROGRESS: at 54.60% examples, 3614 words/s, in_qsize 6, out_qsize 0\n",
      "2017-06-22 14:06:09,421 : INFO : PROGRESS: at 59.22% examples, 3569 words/s, in_qsize 5, out_qsize 0\n",
      "2017-06-22 14:06:10,795 : INFO : PROGRESS: at 61.64% examples, 3635 words/s, in_qsize 6, out_qsize 0\n",
      "2017-06-22 14:06:16,716 : INFO : PROGRESS: at 66.45% examples, 3595 words/s, in_qsize 5, out_qsize 0\n",
      "2017-06-22 14:06:18,266 : INFO : PROGRESS: at 68.85% examples, 3646 words/s, in_qsize 5, out_qsize 0\n",
      "2017-06-22 14:06:23,860 : INFO : PROGRESS: at 73.55% examples, 3623 words/s, in_qsize 5, out_qsize 0\n",
      "2017-06-22 14:06:25,774 : INFO : PROGRESS: at 75.90% examples, 3652 words/s, in_qsize 5, out_qsize 0\n",
      "2017-06-22 14:06:31,054 : INFO : PROGRESS: at 80.53% examples, 3644 words/s, in_qsize 6, out_qsize 0\n",
      "2017-06-22 14:06:33,202 : INFO : PROGRESS: at 82.92% examples, 3660 words/s, in_qsize 5, out_qsize 0\n",
      "2017-06-22 14:06:38,370 : INFO : PROGRESS: at 87.80% examples, 3657 words/s, in_qsize 5, out_qsize 0\n",
      "2017-06-22 14:06:40,604 : INFO : PROGRESS: at 90.14% examples, 3669 words/s, in_qsize 5, out_qsize 0\n",
      "2017-06-22 14:06:46,043 : INFO : PROGRESS: at 94.85% examples, 3655 words/s, in_qsize 3, out_qsize 0\n",
      "2017-06-22 14:06:48,131 : INFO : PROGRESS: at 95.40% examples, 3603 words/s, in_qsize 2, out_qsize 1\n",
      "2017-06-22 14:06:48,134 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2017-06-22 14:06:48,544 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2017-06-22 14:06:48,707 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2017-06-22 14:06:48,709 : INFO : training on 422140 raw words (393111 effective words) took 104.5s, 3761 effective words/s\n",
      "2017-06-22 14:06:48,710 : INFO : saving Word2Vec object under w2vmodel, separately None\n",
      "2017-06-22 14:06:48,713 : INFO : not storing attribute syn0norm\n",
      "2017-06-22 14:06:48,717 : INFO : not storing attribute cum_table\n",
      "2017-06-22 14:06:48,838 : INFO : saved w2vmodel\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done succesfully\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-06-22 14:06:49,109 : INFO : loading Word2Vec object from w2vmodel\n",
      "2017-06-22 14:06:49,215 : INFO : loading wv recursively from w2vmodel.wv.* with mmap=None\n",
      "2017-06-22 14:06:49,216 : INFO : setting ignored attribute syn0norm to None\n",
      "2017-06-22 14:06:49,217 : INFO : setting ignored attribute cum_table to None\n",
      "2017-06-22 14:06:49,219 : INFO : loaded w2vmodel\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done successfully\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-06-22 14:20:25,578 : ERROR : File `'8output-results.py'` not found.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "turn 1/5 is done\n",
      "done succesfully\n",
      "done succesfully\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-06-22 15:02:10,597 : WARNING : Slow version of gensim.models.word2vec is being used\n",
      "2017-06-22 15:02:10,599 : INFO : collecting all words and their counts\n",
      "2017-06-22 15:02:10,600 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2017-06-22 15:02:10,619 : INFO : collected 11672 word types from a corpus of 84428 raw words and 8427 sentences\n",
      "2017-06-22 15:02:10,621 : INFO : Loading a fresh vocabulary\n",
      "2017-06-22 15:02:10,696 : INFO : min_count=1 retains 11672 unique words (100% of original 11672, drops 0)\n",
      "2017-06-22 15:02:10,698 : INFO : min_count=1 leaves 84428 word corpus (100% of original 84428, drops 0)\n",
      "2017-06-22 15:02:10,732 : INFO : deleting the raw counts dictionary of 11672 items\n",
      "2017-06-22 15:02:10,734 : INFO : sample=0.001 downsamples 29 most-common words\n",
      "2017-06-22 15:02:10,736 : INFO : downsampling leaves estimated 78616 word corpus (93.1% of prior 84428)\n",
      "2017-06-22 15:02:10,737 : INFO : estimated required memory for 11672 words and 100 dimensions: 15173600 bytes\n",
      "2017-06-22 15:02:10,769 : INFO : resetting layer weights\n",
      "C:\\Users\\efear\\Anaconda3\\lib\\site-packages\\gensim-2.1.0-py3.6-win-amd64.egg\\gensim\\models\\word2vec.py:789: UserWarning: C extension not loaded for Word2Vec, training will be slow. Install a C compiler and reinstall gensim for fast training.\n",
      "  warnings.warn(\"C extension not loaded for Word2Vec, training will be slow. \"\n",
      "2017-06-22 15:02:10,936 : INFO : training model with 3 workers on 11672 vocabulary and 100 features, using sg=0 hs=0 sample=0.001 negative=5 window=5\n",
      "2017-06-22 15:02:19,054 : INFO : PROGRESS: at 2.49% examples, 1150 words/s, in_qsize 5, out_qsize 0\n",
      "2017-06-22 15:02:27,505 : INFO : PROGRESS: at 9.75% examples, 2250 words/s, in_qsize 6, out_qsize 0\n",
      "2017-06-22 15:02:35,478 : INFO : PROGRESS: at 16.79% examples, 2657 words/s, in_qsize 5, out_qsize 0\n",
      "2017-06-22 15:02:43,639 : INFO : PROGRESS: at 23.84% examples, 2849 words/s, in_qsize 5, out_qsize 0\n",
      "2017-06-22 15:02:51,522 : INFO : PROGRESS: at 31.09% examples, 2982 words/s, in_qsize 5, out_qsize 0\n",
      "2017-06-22 15:02:59,353 : INFO : PROGRESS: at 38.01% examples, 3077 words/s, in_qsize 6, out_qsize 0\n",
      "2017-06-22 15:03:07,734 : INFO : PROGRESS: at 45.21% examples, 3114 words/s, in_qsize 5, out_qsize 0\n",
      "2017-06-22 15:03:16,130 : INFO : PROGRESS: at 52.33% examples, 3141 words/s, in_qsize 6, out_qsize 0\n",
      "2017-06-22 15:03:23,706 : INFO : PROGRESS: at 59.25% examples, 3198 words/s, in_qsize 6, out_qsize 0\n",
      "2017-06-22 15:03:24,830 : INFO : PROGRESS: at 64.07% examples, 3402 words/s, in_qsize 5, out_qsize 0\n",
      "2017-06-22 15:03:31,359 : INFO : PROGRESS: at 66.51% examples, 3241 words/s, in_qsize 5, out_qsize 0\n",
      "2017-06-22 15:03:32,610 : INFO : PROGRESS: at 71.33% examples, 3420 words/s, in_qsize 5, out_qsize 0\n",
      "2017-06-22 15:03:39,099 : INFO : PROGRESS: at 73.66% examples, 3273 words/s, in_qsize 5, out_qsize 0\n",
      "2017-06-22 15:03:40,420 : INFO : PROGRESS: at 75.99% examples, 3329 words/s, in_qsize 5, out_qsize 0\n",
      "2017-06-22 15:03:48,375 : INFO : PROGRESS: at 80.52% examples, 3249 words/s, in_qsize 6, out_qsize 0\n",
      "2017-06-22 15:03:50,055 : INFO : PROGRESS: at 83.00% examples, 3288 words/s, in_qsize 6, out_qsize 0\n",
      "2017-06-22 15:03:58,434 : INFO : PROGRESS: at 87.87% examples, 3204 words/s, in_qsize 6, out_qsize 0\n",
      "2017-06-22 15:04:00,056 : INFO : PROGRESS: at 90.25% examples, 3242 words/s, in_qsize 5, out_qsize 0\n",
      "2017-06-22 15:04:07,454 : INFO : PROGRESS: at 94.97% examples, 3196 words/s, in_qsize 3, out_qsize 0\n",
      "2017-06-22 15:04:08,902 : INFO : PROGRESS: at 97.27% examples, 3235 words/s, in_qsize 2, out_qsize 1\n",
      "2017-06-22 15:04:08,904 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2017-06-22 15:04:09,310 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2017-06-22 15:04:09,316 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2017-06-22 15:04:09,317 : INFO : training on 422140 raw words (393090 effective words) took 118.4s, 3321 effective words/s\n",
      "2017-06-22 15:04:09,328 : INFO : saving Word2Vec object under w2vmodel, separately None\n",
      "2017-06-22 15:04:09,329 : INFO : not storing attribute syn0norm\n",
      "2017-06-22 15:04:09,331 : INFO : not storing attribute cum_table\n",
      "2017-06-22 15:04:09,509 : INFO : saved w2vmodel\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done succesfully\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-06-22 15:04:09,830 : INFO : loading Word2Vec object from w2vmodel\n",
      "2017-06-22 15:04:09,936 : INFO : loading wv recursively from w2vmodel.wv.* with mmap=None\n",
      "2017-06-22 15:04:09,937 : INFO : setting ignored attribute syn0norm to None\n",
      "2017-06-22 15:04:09,938 : INFO : setting ignored attribute cum_table to None\n",
      "2017-06-22 15:04:09,940 : INFO : loaded w2vmodel\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done successfully\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32mC:\\Users\\efear\\Documents\\GitHub\\Sentiment-Analysis-on-Movie-Reviews\\7calculate-test.ipynb\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mPhrase\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m             \u001b[1;31m#chech if that phrase is in the train set alreadt\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m             \u001b[0mfind\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mPhrase\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mPhrase\u001b[0m\u001b[1;33m==\u001b[0m\u001b[0mrow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mPhrase\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfind\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m                 \u001b[1;31m#if already in train set assign the score directly\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\efear\\Anaconda3\\lib\\site-packages\\pandas\\core\\series.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    642\u001b[0m             \u001b[0mkey\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_bool_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    643\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 644\u001b[0;31m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_with\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    645\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    646\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_get_with\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\efear\\Anaconda3\\lib\\site-packages\\pandas\\core\\series.py\u001b[0m in \u001b[0;36m_get_with\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    678\u001b[0m                     \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_values\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    679\u001b[0m             \u001b[1;32melif\u001b[0m \u001b[0mkey_type\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'boolean'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 680\u001b[0;31m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_values\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    681\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    682\u001b[0m                 \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\efear\\Anaconda3\\lib\\site-packages\\pandas\\core\\series.py\u001b[0m in \u001b[0;36m_get_values\u001b[0;34m(self, indexer)\u001b[0m\n\u001b[1;32m    709\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_get_values\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    710\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 711\u001b[0;31m             return self._constructor(self._data.get_slice(indexer),\n\u001b[0m\u001b[1;32m    712\u001b[0m                                      fastpath=True).__finalize__(self)\n\u001b[1;32m    713\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\efear\\Anaconda3\\lib\\site-packages\\pandas\\core\\internals.py\u001b[0m in \u001b[0;36mget_slice\u001b[0;34m(self, slobj, axis)\u001b[0m\n\u001b[1;32m   4133\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mIndexError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Requested axis not found in manager\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   4134\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4135\u001b[0;31m         return self.__class__(self._block._slice(slobj),\n\u001b[0m\u001b[1;32m   4136\u001b[0m                               self.index[slobj], fastpath=True)\n\u001b[1;32m   4137\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\efear\\Anaconda3\\lib\\site-packages\\pandas\\core\\internals.py\u001b[0m in \u001b[0;36m_slice\u001b[0;34m(self, slicer)\u001b[0m\n\u001b[1;32m    250\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_slice\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mslicer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    251\u001b[0m         \u001b[1;34m\"\"\" return a slice of my values \"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 252\u001b[0;31m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mslicer\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    253\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    254\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mreshape_nd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mref_items\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmgr\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-06-22 15:04:44,045 : ERROR : File `'8output-results.py'` not found.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "turn 2/5 is done\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "path=os.getcwd()+\"\\\\data\\\\\"\n",
    "\n",
    "#get all 5 dataset parts to list \"dfset\"\n",
    "dfset=[]\n",
    "for x in range (1,6):\n",
    "    dfset.append(pd.read_csv(path+str(x)+\"df.csv\",sep=\"\\t\"))\n",
    "    \n",
    "for x in range (0,5):\n",
    "    dfset[x].drop('Unnamed: 0', 1).reset_index(drop=True)\n",
    "\n",
    "for x in range(0,len(dfset)):\n",
    "    test=dfset[0]\n",
    "    del dfset[0]\n",
    "    train=pd.concat(dfset)\n",
    "    train.to_csv(\"data/train.csv\", sep='\\t')\n",
    "    test.to_csv(\"data/test.csv\", sep='\\t')\n",
    "    dfset.append(test)\n",
    "    %run \"3clean-train.ipynb\"\n",
    "    %run \"4get-sentences.ipynb\"\n",
    "    %run \"5get-w2v-model.ipynb\"\n",
    "    %run \"6get-words.ipynb\"\n",
    "    %run \"7calculate-test.ipynb\"\n",
    "    %run \"8output-results.ipynb\"\n",
    "    print(\"turn \"+str(x+1)+\"/5 is done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2, 3, 4, 1]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a=[1,2,3,4]\n",
    "del a[0]\n",
    "a.append(1)\n",
    "a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clean train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done succesfully\n"
     ]
    }
   ],
   "source": [
    "%run \"3clean-train.ipynb\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prepare train data for w2v.\n",
    "Takes input \"../data/train.csv\"\n",
    "Outputs \"../data/trainw2v.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done succesfully\n"
     ]
    }
   ],
   "source": [
    "%run \"4get-sentences.ipynb\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\efear\\Anaconda3\\lib\\site-packages\\gensim-2.1.0-py3.6-win-amd64.egg\\gensim\\utils.py:860: UserWarning: detected Windows; aliasing chunkize to chunkize_serial\n",
      "  warnings.warn(\"detected Windows; aliasing chunkize to chunkize_serial\")\n",
      "Slow version of gensim.models.doc2vec is being used\n",
      "2017-06-15 17:05:40,724 : WARNING : Slow version of gensim.models.word2vec is being used\n",
      "2017-06-15 17:05:40,725 : INFO : collecting all words and their counts\n",
      "2017-06-15 17:05:40,727 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2017-06-15 17:05:40,747 : INFO : collected 11658 word types from a corpus of 84512 raw words and 8416 sentences\n",
      "2017-06-15 17:05:40,749 : INFO : Loading a fresh vocabulary\n",
      "2017-06-15 17:05:40,777 : INFO : min_count=1 retains 11658 unique words (100% of original 11658, drops 0)\n",
      "2017-06-15 17:05:40,778 : INFO : min_count=1 leaves 84512 word corpus (100% of original 84512, drops 0)\n",
      "2017-06-15 17:05:40,815 : INFO : deleting the raw counts dictionary of 11658 items\n",
      "2017-06-15 17:05:40,816 : INFO : sample=0.001 downsamples 28 most-common words\n",
      "2017-06-15 17:05:40,818 : INFO : downsampling leaves estimated 78702 word corpus (93.1% of prior 84512)\n",
      "2017-06-15 17:05:40,820 : INFO : estimated required memory for 11658 words and 100 dimensions: 15155400 bytes\n",
      "2017-06-15 17:05:40,853 : INFO : resetting layer weights\n",
      "C:\\Users\\efear\\Anaconda3\\lib\\site-packages\\gensim-2.1.0-py3.6-win-amd64.egg\\gensim\\models\\word2vec.py:789: UserWarning: C extension not loaded for Word2Vec, training will be slow. Install a C compiler and reinstall gensim for fast training.\n",
      "  warnings.warn(\"C extension not loaded for Word2Vec, training will be slow. \"\n",
      "2017-06-15 17:05:41,019 : INFO : training model with 3 workers on 11658 vocabulary and 100 features, using sg=0 hs=0 sample=0.001 negative=5 window=5\n",
      "2017-06-15 17:05:49,716 : INFO : PROGRESS: at 2.40% examples, 1069 words/s, in_qsize 5, out_qsize 0\n",
      "2017-06-15 17:05:58,283 : INFO : PROGRESS: at 9.77% examples, 2159 words/s, in_qsize 5, out_qsize 0\n",
      "2017-06-15 17:06:06,167 : INFO : PROGRESS: at 16.75% examples, 2593 words/s, in_qsize 6, out_qsize 0\n",
      "2017-06-15 17:06:13,980 : INFO : PROGRESS: at 23.80% examples, 2826 words/s, in_qsize 5, out_qsize 0\n",
      "2017-06-15 17:06:15,044 : INFO : PROGRESS: at 28.63% examples, 3285 words/s, in_qsize 5, out_qsize 0\n",
      "2017-06-15 17:06:21,890 : INFO : PROGRESS: at 30.98% examples, 2963 words/s, in_qsize 6, out_qsize 0\n",
      "2017-06-15 17:06:23,079 : INFO : PROGRESS: at 35.72% examples, 3321 words/s, in_qsize 5, out_qsize 0\n",
      "2017-06-15 17:06:30,093 : INFO : PROGRESS: at 37.95% examples, 3036 words/s, in_qsize 6, out_qsize 0\n",
      "2017-06-15 17:06:31,519 : INFO : PROGRESS: at 40.21% examples, 3134 words/s, in_qsize 5, out_qsize 0\n",
      "2017-06-15 17:06:40,172 : INFO : PROGRESS: at 45.15% examples, 2990 words/s, in_qsize 6, out_qsize 0\n",
      "2017-06-15 17:06:41,982 : INFO : PROGRESS: at 47.54% examples, 3054 words/s, in_qsize 5, out_qsize 0\n",
      "2017-06-15 17:06:51,048 : INFO : PROGRESS: at 52.32% examples, 2925 words/s, in_qsize 6, out_qsize 0\n",
      "2017-06-15 17:06:52,599 : INFO : PROGRESS: at 54.70% examples, 2991 words/s, in_qsize 5, out_qsize 0\n",
      "2017-06-15 17:07:00,219 : INFO : PROGRESS: at 59.18% examples, 2939 words/s, in_qsize 5, out_qsize 0\n",
      "2017-06-15 17:07:01,994 : INFO : PROGRESS: at 61.60% examples, 2989 words/s, in_qsize 6, out_qsize 0\n",
      "2017-06-15 17:07:09,513 : INFO : PROGRESS: at 66.46% examples, 2946 words/s, in_qsize 6, out_qsize 0\n",
      "2017-06-15 17:07:11,473 : INFO : PROGRESS: at 68.82% examples, 2985 words/s, in_qsize 5, out_qsize 0\n",
      "2017-06-15 17:07:18,519 : INFO : PROGRESS: at 73.62% examples, 2960 words/s, in_qsize 6, out_qsize 0\n",
      "2017-06-15 17:07:20,531 : INFO : PROGRESS: at 75.93% examples, 2994 words/s, in_qsize 6, out_qsize 0\n",
      "2017-06-15 17:07:27,196 : INFO : PROGRESS: at 80.44% examples, 2981 words/s, in_qsize 5, out_qsize 0\n",
      "2017-06-15 17:07:29,605 : INFO : PROGRESS: at 82.92% examples, 3001 words/s, in_qsize 6, out_qsize 0\n",
      "2017-06-15 17:07:36,627 : INFO : PROGRESS: at 87.74% examples, 2979 words/s, in_qsize 6, out_qsize 0\n",
      "2017-06-15 17:07:39,160 : INFO : PROGRESS: at 90.11% examples, 2994 words/s, in_qsize 5, out_qsize 0\n",
      "2017-06-15 17:07:44,917 : INFO : PROGRESS: at 94.89% examples, 3005 words/s, in_qsize 3, out_qsize 0\n",
      "2017-06-15 17:07:47,110 : INFO : PROGRESS: at 95.50% examples, 2973 words/s, in_qsize 2, out_qsize 1\n",
      "2017-06-15 17:07:47,112 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2017-06-15 17:07:47,288 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2017-06-15 17:07:47,450 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2017-06-15 17:07:47,452 : INFO : training on 422560 raw words (393513 effective words) took 126.4s, 3113 effective words/s\n",
      "2017-06-15 17:07:47,453 : INFO : saving Word2Vec object under w2vmodel, separately None\n",
      "2017-06-15 17:07:47,455 : INFO : not storing attribute syn0norm\n",
      "2017-06-15 17:07:47,456 : INFO : not storing attribute cum_table\n",
      "2017-06-15 17:07:47,573 : INFO : saved w2vmodel\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done succesfully\n"
     ]
    }
   ],
   "source": [
    "%run \"5get-w2v-model.ipynb\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%run \"6get-words.ipynb\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%run \"7calculate-test.ipynb\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%run \"8output-results\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done successfully\n"
     ]
    }
   ],
   "source": [
    "print(\"done successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
