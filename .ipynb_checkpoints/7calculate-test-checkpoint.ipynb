{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PURPOSE OF CODE\n",
    "\n",
    "The test set scores are assigned and error is calculated as new columns for all test phrases."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PROCESS NOTES\n",
    "\n",
    "WILL BE DONE\n",
    "- recursive search for word groups may be written\n",
    "- most dominant words may extracted for better score assginment\n",
    "\n",
    "DONE\n",
    "- test phrase is searched in train set\n",
    "- if no found, in test phrase word group, try to find longest sub phrase that is in train set\n",
    "- if sub phrase found in train set, search for remaining words seperately on train set, if no found get the closest word's sentiment score using w2v model created for each one and average all scores get."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import gensim, logging\n",
    "import pandas as pd\n",
    "model= gensim.models.Word2Vec.load(\"w2vmodel\")\n",
    "words=pd.read_csv('data/words.csv',sep=\"\\t\")\n",
    "train=pd.read_csv('data/train-clean.csv',sep=\"\\t\")\n",
    "test=pd.read_csv('data/test.csv',sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>PhraseId</th>\n",
       "      <th>SentenceId</th>\n",
       "      <th>Phrase</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>calculation</th>\n",
       "      <th>error</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>69043</td>\n",
       "      <td>3507</td>\n",
       "      <td>glorious goofi way</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>13402</td>\n",
       "      <td>577</td>\n",
       "      <td>start wonder</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>71229</td>\n",
       "      <td>3635</td>\n",
       "      <td>green threw medic equip window not becaus wa p...</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>102596</td>\n",
       "      <td>5401</td>\n",
       "      <td>end no one in audienc film seem realli care</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>7157</td>\n",
       "      <td>292</td>\n",
       "      <td>even aim shock</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  PhraseId  SentenceId  \\\n",
       "0           0     69043        3507   \n",
       "1           1     13402         577   \n",
       "2           2     71229        3635   \n",
       "3           3    102596        5401   \n",
       "4           4      7157         292   \n",
       "\n",
       "                                              Phrase  Sentiment  calculation  \\\n",
       "0                                 glorious goofi way          3          NaN   \n",
       "1                                       start wonder          2          NaN   \n",
       "2  green threw medic equip window not becaus wa p...          2          NaN   \n",
       "3        end no one in audienc film seem realli care          0          NaN   \n",
       "4                                     even aim shock          2          NaN   \n",
       "\n",
       "   error  \n",
       "0    NaN  \n",
       "1    NaN  \n",
       "2    NaN  \n",
       "3    NaN  \n",
       "4    NaN  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test['calculation'] = pd.Series(np.NaN , index=test.index)\n",
    "test['error'] = pd.Series(np.NaN , index=test.index)\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from IPython.core.debugger import Tracer; debug = Tracer()\n",
    "from scipy.spatial import distance\n",
    "  \n",
    "\n",
    "phrase=[]\n",
    "tmp1_phrase=[]\n",
    "tmp2_phrase=[]\n",
    "attribution_count=0\n",
    "attribution_sum=0\n",
    "\n",
    "\n",
    "for indx,row in test.iterrows():\n",
    "    #check if phrase is in string type\n",
    "    if isinstance(row.Phrase,str):\n",
    "        #check if there is something\n",
    "        if len(row.Phrase):\n",
    "            #chech if that phrase is in the train set alreadt\n",
    "            find=train.Phrase[train.Phrase==row.Phrase]\n",
    "            if len(find.index):\n",
    "                #if already in train set assign the score directly\n",
    "                test.loc[indx,\"calculation\"]=train.loc[find.index[0],\"Sentiment\"]\n",
    "            else:\n",
    "                attribution_count=0\n",
    "                attribution_sum=0\n",
    "                phrase=row.Phrase.split()\n",
    "                length=len(phrase)\n",
    "                #if phrase contains single word\n",
    "                if length>1:\n",
    "                    tmp=1\n",
    "                    # with tmp+1<length words could be checked seperately\n",
    "                    while tmp<length:\n",
    "                        for x in range(0,tmp+1):\n",
    "                            #devide phrase into 2 part one is the major word group that will be searched as it is\n",
    "                            #other group words will be scored seperately\n",
    "                            tmp1_phrase=phrase[x:(length-tmp+x)]\n",
    "                            tmp2_phrase=list(set(phrase)-set(tmp1_phrase))\n",
    "                            find=train.Phrase[train.Phrase==\" \".join(tmp1_phrase)]\n",
    "                            a=len(find.index)\n",
    "                            #check if word group is found if found break\n",
    "                            if a:\n",
    "                                break\n",
    "                        #if found calculate score\n",
    "                        if a:\n",
    "                            attribution_count+=1\n",
    "                            attribution_sum+=train.loc[find.index[0],\"Sentiment\"]\n",
    "                            for y in tmp2_phrase:\n",
    "                                find=train.Phrase[train.Phrase==y]\n",
    "                                if len(find.index):\n",
    "                                    attribution_count+=1\n",
    "                                    attribution_sum+=train.loc[find.index[0],\"Sentiment\"]\n",
    "                                else:\n",
    "                                    try:\n",
    "                                        vec=model[y]\n",
    "                                        tmpvec=model[words.loc[0,\"Phrase\"]]\n",
    "                                        tmpindx=0\n",
    "                                        dist=distance.euclidean(vec,tmpvec)\n",
    "                                        for indx1,row in words.iterrows():\n",
    "                                            tmpdist=distance.euclidean(vec,model[row.Phrase])\n",
    "                                            if tmpdist<dist:\n",
    "                                                dist=tmpdist\n",
    "                                                tmpvec=model[row.Phrase]\n",
    "                                                tmpindx=indx1\n",
    "                                        attribution_count+=1\n",
    "                                        attribution_sum+=words.loc[tmpindx,\"Sentiment\"]\n",
    "                                    except:\n",
    "                                        pass\n",
    "                            break\n",
    "                        tmp+=1\n",
    "                #if single word phrase calculate score\n",
    "                else:\n",
    "                    try:\n",
    "                        vec=model[row.Phrase]\n",
    "                        tmpvec=model[words.loc[0,\"Phrase\"]]\n",
    "                        tmpindx=0\n",
    "                        dist=distance.euclidean(vec,tmpvec)\n",
    "                        for indx1,row in words.iterrows():\n",
    "                            tmpdist=distance.euclidean(vec,model[row.Phrase])\n",
    "                            if tmpdist<dist:\n",
    "                                dist=tmpdist\n",
    "                                tmpvec=model[row.Phrase]\n",
    "                                tmpindx=indx1\n",
    "                        attribution_count+=1\n",
    "                        attribution_sum+=words.loc[tmpindx,\"Sentiment\"]\n",
    "                    except:\n",
    "                        pass\n",
    "                if attribution_count!=0:\n",
    "                    test.loc[indx,\"calculation\"]=attribution_sum/attribution_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for indx,row in test.iterrows():\n",
    "    test.loc[indx,\"error\"]= abs(row.Sentiment-row.calculation)\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test = test.drop('Unnamed: 0', 1)\n",
    "test.to_csv(\"data/test-calculated.csv\", sep='\\t')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
